{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 101 개의 categories\n",
    "# 이미지 크기가 모두 달라서, resize 해줘야함.\n",
    "# 이미지 불러올 때 쓰는 library\n",
    "from PIL import Image\n",
    "import os,glob\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "caltech_dir = \"101_ObjectCategories\"\n",
    "# 101 개는 너무 많으니까 5개 예측하는 것 먼저.\n",
    "# okapi - 말\n",
    "categories = [\"brain\", \"camera\", \"crayfish\", \"helicopter\", \"okapi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class=len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space of data\n",
    "X=[]\n",
    "y=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width=224; image_height=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# image load\n",
    "for i,f in enumerate(categories):\n",
    "    #label one hot encoding\n",
    "    label=[0 for j in range(n_class)]\n",
    "    label[i]=1\n",
    "    images_list=caltech_dir+\"/\"+f\n",
    "    # 폴더 내 파일들을 가져옴\n",
    "    files=glob.glob(images_list+\"/*.jpg\")\n",
    "    for i, fname in enumerate(files):\n",
    "        img=Image.open(fname)\n",
    "        # 색상이 있음으로 RGB로 변환\n",
    "        img=img.convert(\"RGB\")\n",
    "        img=img.resize((image_width,image_height),3)\n",
    "        data=np.asarray(img)\n",
    "        X.append(data)\n",
    "        y.append(label)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 로 바꿔줘야함.\n",
    "X=np.array(X); y=np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train, test set 분할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y,test_size=0.33)\n",
    "\n",
    "# 정규화를 시켜줘야한다! /225로 나누기 \n",
    "X_train=X_train.astype(\"float\")/225\n",
    "X_test=X_test.astype(\"float\")/225"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter setting and training model with keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfilter=bsize=32; opt=['adam','rmsprop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sora\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D,ZeroPadding2D,MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BASIC MODEL (Basic CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](basic_model.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(nfilter, (3, 3), padding=\"same\", input_shape = X_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(2*nfilter, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(2*nfilter, (3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_class))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt[1], metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 3s 25ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "loss = 0.5080604699620029 , accuracy = 0.8000000621143141 , baseline error: 20.00%\n"
     ]
    }
   ],
   "source": [
    "basic_model=basic_model()\n",
    "\n",
    "\n",
    "score = basic_model.evaluate(X_test, Y_test, batch_size=bsize)\n",
    "print(\"\\n\\n\\n\\nloss =\", score[0], \", accuracy =\", score[1],\", baseline error: %.2f%%\" % (100-score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a=[]\n",
    "Y_a=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# image load\n",
    "for i,f in enumerate(categories):\n",
    "    #label one hot encoding\n",
    "    label=[0 for j in range(n_class)]\n",
    "    label[i]=1\n",
    "    images_list=caltech_dir+\"/\"+f\n",
    "    # 폴더 내 파일들을 가져옴\n",
    "    files=glob.glob(images_list+\"/*.jpg\")\n",
    "    for i, fname in enumerate(files):\n",
    "        img=Image.open(fname)\n",
    "        # 색상이 있음으로 RGB로 변환\n",
    "        img=img.convert(\"RGB\")\n",
    "        img=img.resize((227,227),3)\n",
    "        data=np.asarray(img)\n",
    "        X_a.append(data)\n",
    "        Y_a.append(label)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 로 바꿔줘야함.\n",
    "X_a=np.array(X_a); Y_a=np.array(Y_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a, X_test_a, Y_train_a, Y_test_a = train_test_split(X_a, Y_a,test_size=0.33)\n",
    "\n",
    "# 정규화를 시켜줘야한다! /227로 나누기 \n",
    "X_train_a=X_train_a.astype(\"float\")/227\n",
    "X_test_a=X_test_a.astype(\"float\")/227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Alexnet():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(96,(11,11),activation='relu',strides=(4,4),input_shape=(227, 227, 3)))\n",
    "    model.add(MaxPooling2D((3, 3),strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(256,(5,5),activation='relu',strides=(1,1)))\n",
    "    model.add(MaxPooling2D((3, 3),strides=(2,2)))\n",
    "    model.add(Conv2D(384,(3,3),activation='relu',strides=(1,1)))\n",
    "    model.add(Conv2D(384,(3,3),activation='relu',strides=(1,1)))\n",
    "    model.add(Conv2D(256,(3,3),activation='relu',strides=(1,1)))\n",
    "    model.add(MaxPooling2D((3, 3),strides=(2,2),padding='valid'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt[1], metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 9ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "loss = 0.501481176468364 , accuracy = 0.800000011920929 , baseline error: 20.00%\n"
     ]
    }
   ],
   "source": [
    "alex=Alexnet()\n",
    "\n",
    "\n",
    "score = alex.evaluate(X_test_a, Y_test_a, batch_size=bsize)\n",
    "print(\"\\n\\n\\n\\nloss =\", score[0], \", accuracy =\", score[1],\", baseline error: %.2f%%\" % (100-score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - VGG16(layer)\n",
    "\n",
    "망의 깊이가 어떤 영향을 주는지 연구를 하기 위해서 설계된 Network\n",
    "convolution 3x3 로만 정하고, 깊이를 늘림.\n",
    "하지만 어마어마한 parameter수, (fully connected layer가 3개고 pooling을 거친 뒤에는 feature map 개수가 2배로 커짐)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](vgg16.png)\n",
    "\n",
    "https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_16():\n",
    "    model = Sequential()\n",
    "    # 226 x 226 x 3\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224,3)))\n",
    "    # 224 x 224 x 64\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    # 226 x 226 x 64\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    # 224 x 224 x 64\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    # 사이즈가 /2로 줄어듬.\n",
    "    # (224-2)/2+1 = 122\n",
    "    # 112 x 122 x 64\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    # 114 x 114 x 64\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    # 112 x 112 x 128\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    # 114 x 114 x 128\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    # 112 x 112 x 128\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    # (112-2)/2+1= 56 \n",
    "    # 56 x 56 x 128\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    # 58 x 58 x 128\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    # 56 x 56 x 256\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    # 58 x 58 x 256\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    # 56 x 56 x 256 (계속 해서 이미지 크기가 보존 되고 있음)\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    # 56 x 56 x 256\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    # 56 x 56 x 256\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    # (56-2)/2+1= 28 x 28x 256\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    # 30 x 30 x 256\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    # 28 x 28 x 512\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    # 30 x 30 x 512\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    # 28 x 28 x 512\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    # 30 x 30 x 512\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    # 28 x 28 x 512\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    # (28-2)/2+1 =14 x 14 x 512\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    # 16 x 16 x 512\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    # 14 x 14 x 512\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    # 16 x 16 x 512\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    # 14 x 14 x 512\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    # 16 x 16 x 512\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    # 14 x 14 x 512\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    # (14-2)/2+1 = 7 x 7 x 512\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # 4096- 5\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt[1], metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 25s 221ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "loss = 0.5004072712178815 , accuracy = 0.8000000621143141 , baseline error: 20.00%\n"
     ]
    }
   ],
   "source": [
    "vgg=VGG_16()\n",
    "\n",
    "\n",
    "score = vgg.evaluate(X_test, Y_test, batch_size=bsize)\n",
    "print(\"\\n\\n\\n\\nloss =\", score[0], \", accuracy =\", score[1],\", baseline error: %.2f%%\" % (100-score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic -> alexnet -> vgg 로 갈 수록 loss가 준 것을 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
