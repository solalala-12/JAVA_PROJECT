{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 불러온 이미지 선처리 하기 위한 단계 (ToTensor : 이미지를 텐서 형태로)\n",
    "# 전처리 할때 많이 사용한다. \n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "# PIL image (H x W x C) -> Tensor (C x H x W)\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform)\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                       train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# 데이터를 한번에 넣어서 학습을 시킬 수 없음, 시간과 메모리를 너무 많이 잡아 먹는다.\n",
    "# batch_size=4 4개씩 잘라서 분석 진행.\n",
    "# shuffle은 반복될 때 마다 데이터 재 정립 유무\n",
    "# drop_last 는 batch_size로 데이터가 나눠 떨어지지 않을 때 그 값들을 버릴 건지\n",
    "trainloader = DataLoader(trainset, \n",
    "                         batch_size=4,\n",
    "                         shuffle=True, \n",
    "                         drop_last=False)\n",
    "\n",
    "testloader = DataLoader(testset, \n",
    "                        batch_size=4,\n",
    "                        shuffle=False,\n",
    "                        drop_last=False)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "torch.Size([4, 3, 32, 32])\n",
      "tensor([3, 4, 4, 0])\n"
     ]
    }
   ],
   "source": [
    "#iterator, 데이터를 하나씩 돌면서 탐색한다.\n",
    "trainiter = iter(trainloader)\n",
    "images, labels = trainiter.next()\n",
    "\n",
    "print(len(trainloader))\n",
    "print(images.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter setting\n",
    "src = {'input_size':3*32*32,\n",
    "       'hidden_size':50,\n",
    "       'output_size':10,\n",
    "       'num_epochs':2,\n",
    "       'batch_size':100,\n",
    "       'learning_rate':1e-3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# nn에 필요한 다양한 함수들을 제공한다.\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TobigsNet(nn.Module):\n",
    "    def __init__(self, src):\n",
    "        super(TobigsNet, self).__init__()   \n",
    "        ## sequential layer\n",
    "        # 선형->Relu->선형->softmax \n",
    "        self.model = nn.Sequential(nn.Linear(src['input_size'], src['hidden_size']),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(src['hidden_size'], src['output_size']),\n",
    "                     nn.Softmax())\n",
    "        \n",
    "    \n",
    "    def forward(self, img):\n",
    "        # 차원을 바꾼다.\n",
    "\n",
    "        x = img.view(img.shape[0], -1)\n",
    "        y = self.model(x)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sora\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "model = TobigsNet(src)\n",
    "# oupput \n",
    "y = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# loss 함수로는 likelidhood 사용\n",
    "criterion = nn.NLLLoss()\n",
    "# descent gradient \n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      src['learning_rate'], \n",
    "                      momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]C:\\Users\\sora\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [1000/12000], Loss: -0.1522\n",
      "Epoch [1/2], Step [2000/12000], Loss: -0.2144\n",
      "Epoch [1/2], Step [3000/12000], Loss: -0.2555\n",
      "Epoch [1/2], Step [4000/12000], Loss: -0.2860\n",
      "Epoch [1/2], Step [5000/12000], Loss: -0.2876\n",
      "Epoch [1/2], Step [6000/12000], Loss: -0.2982\n",
      "Epoch [1/2], Step [7000/12000], Loss: -0.3167\n",
      "Epoch [1/2], Step [8000/12000], Loss: -0.3174\n",
      "Epoch [1/2], Step [9000/12000], Loss: -0.3181\n",
      "Epoch [1/2], Step [10000/12000], Loss: -0.3185\n",
      "Epoch [1/2], Step [11000/12000], Loss: -0.3190\n",
      "Epoch [1/2], Step [12000/12000], Loss: -0.3357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:40<00:40, 40.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Step [1000/12000], Loss: -0.3566\n",
      "Epoch [2/2], Step [2000/12000], Loss: -0.3568\n",
      "Epoch [2/2], Step [3000/12000], Loss: -0.3537\n",
      "Epoch [2/2], Step [4000/12000], Loss: -0.3640\n",
      "Epoch [2/2], Step [5000/12000], Loss: -0.3673\n",
      "Epoch [2/2], Step [6000/12000], Loss: -0.3648\n",
      "Epoch [2/2], Step [7000/12000], Loss: -0.3732\n",
      "Epoch [2/2], Step [8000/12000], Loss: -0.3722\n",
      "Epoch [2/2], Step [9000/12000], Loss: -0.3895\n",
      "Epoch [2/2], Step [10000/12000], Loss: -0.3726\n",
      "Epoch [2/2], Step [11000/12000], Loss: -0.3747\n",
      "Epoch [2/2], Step [12000/12000], Loss: -0.3774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:20<00:00, 40.13s/it]\n"
     ]
    }
   ],
   "source": [
    "#진행 표시바\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in tqdm(range(src['num_epochs'])):\n",
    "    #epoch 마다 loss 갱신해야 함으로, current loss =0으로 지정!\n",
    "    current_loss = 0.0\n",
    "#     model.train(True)\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # loss를 최소화 하는 방향으로, backward gradient descent weight 업데이트!\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        step = i + 1\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        if step % 1000 == 0 and step != 0:     # print every 1000 mini-batches\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' %\n",
    "                  #  평균 loss를 사용해야 한다.\n",
    "                  (epoch + 1, src['num_epochs'], step, len(trainloader)//1000 * 1000, current_loss / 1000))\n",
    "            current_loss = 0.0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sora\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2500 test images: 39 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "# test set을 돈다!\n",
    "for i, data in enumerate(testloader):\n",
    "    inputs, labels = data\n",
    "#     images = images.view(-1, 28*28)\n",
    "    outputs = model(inputs)\n",
    "    # outputs 확률에서 가장 크게 나온 값을 가져온다!\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.shape[0]\n",
    "    # 만약 두 값이 같으면 sum에 +1 ~!\n",
    "    \n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "# 몇 %를 맞췄는지.\n",
    "print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
